{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 0,
        "height": 2,
        "hidden": false,
        "row": 0,
        "width": 12
       },
       "report_default": {
        "hidden": false
       }
      }
     }
    }
   },
   "source": [
    "# **Identifikation von Problemstellen in Java-Anwedungen**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 0,
        "height": 4,
        "hidden": true,
        "row": 2,
        "width": 12
       },
       "report_default": {
        "hidden": true
       }
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "#Graphdatenbankanbindung\n",
    "import py2neo\n",
    "\n",
    "graph = py2neo.Graph(bolt=True, host='localhost', user='neo4j', password='neo4j')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 0,
        "height": 4,
        "hidden": true,
        "row": 2,
        "width": 12
       },
       "report_default": {
        "hidden": true
       }
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "#html für pygal laden\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "base_html = \"\"\"\n",
    "<!DOCTYPE html>\n",
    "<html>\n",
    "  <head>\n",
    "  <script type=\"text/javascript\" src=\"http://kozea.github.com/pygal.js/javascripts/svg.jquery.js\"></script>\n",
    "  <script type=\"text/javascript\" src=\"https://kozea.github.io/pygal.js/2.0.x/pygal-tooltips.min.js\"\"></script>\n",
    "  </head>\n",
    "  <body>\n",
    "    <figure>\n",
    "      {rendered_chart}\n",
    "    </figure>\n",
    "  </body>\n",
    "</html>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 0,
        "height": 12,
        "hidden": false,
        "row": 2,
        "width": 4
       },
       "report_default": {
        "hidden": false
       }
      }
     }
    }
   },
   "source": [
    "## Systemgröße\n",
    "In dem Gauge Systemgröße wird das Programm eingeordnet nach der Größe seines Systems.\n",
    "Die Einteilung erfolgt auf Grundlage der Anzahl der Quelltextzeilen.\n",
    "Anhand dieser Analyse ist es möglich, das Programm grob im Hinblick auf Komplexität und Größe einzuordnen.\n",
    "\n",
    "*sehr klein: kleiner gleich 10000; klein: zwischen 10000 und 50000; mittel: zwischen 50000 und 200000; groß: zwischen 200000 und 500000; sehr groß: über 500000*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 4,
        "height": 12,
        "hidden": false,
        "row": 2,
        "width": 8
       },
       "report_default": {
        "hidden": false
       }
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "#Systemgröße\n",
    "\n",
    "#Cypher Abfrage\n",
    "import pandas as pd\n",
    "\n",
    "query =\"MATCH (t:Type)-[:HAS_SOURCE]->(f), (t)-[:DECLARES]->(m:Method) RETURN sum(m.effectiveLineCount) as loc\"\n",
    "df = pd.DataFrame(graph.run(query).data())\n",
    "\n",
    "#Visualisierung\n",
    "import matplotlib\n",
    "from matplotlib import cm\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.patches import Circle, Wedge, Rectangle\n",
    "import numpy as np\n",
    "import plotly.plotly as py\n",
    "import plotly.tools as tls\n",
    "\n",
    "def degree_range(n): \n",
    "    start = np.linspace(0,180,n+1, endpoint=True)[0:-1]\n",
    "    end = np.linspace(0,180,n+1, endpoint=True)[1::]\n",
    "    mid_points = start + ((end-start)/2.)\n",
    "    return np.c_[start, end], mid_points\n",
    "\n",
    "def rot_text(ang): \n",
    "    rotation = np.degrees(np.radians(ang) * np.pi / np.pi - np.radians(90))\n",
    "    return rotation\n",
    "\n",
    "def gauge(labels=['Sehr klein','Klein','Mittel','Groß','Sehr Groß'], \\\n",
    "          colors='jet_r', arrow=1, title='', fname=False): \n",
    "    \n",
    "    \"\"\"\n",
    "    some sanity checks first\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    N = len(labels)\n",
    "    \n",
    "    if arrow > N: \n",
    "        raise Exception(\"\\n\\nThe category ({}) is greated than \\\n",
    "        the length\\nof the labels ({})\".format(arrow, N))\n",
    " \n",
    "    \n",
    "    \"\"\"\n",
    "    if colors is a string, we assume it's a matplotlib colormap\n",
    "    and we discretize in N discrete colors \n",
    "    \"\"\"\n",
    "    \n",
    "    if isinstance(colors, str):\n",
    "        cmap = cm.get_cmap(colors, N)\n",
    "        cmap = cmap(np.arange(N))\n",
    "        colors = cmap[::-1,:].tolist()\n",
    "    if isinstance(colors, list): \n",
    "        if len(colors) == N:\n",
    "            colors = colors[::-1]\n",
    "        else: \n",
    "            raise Exception(\"\\n\\nnumber of colors {} not equal \\\n",
    "            to number of categories{}\\n\".format(len(colors), N))\n",
    "\n",
    "    \"\"\"\n",
    "    begins the plotting\n",
    "    \"\"\"\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    ang_range, mid_points = degree_range(N)\n",
    "\n",
    "    labels = labels[::-1]\n",
    "    \n",
    "    \"\"\"\n",
    "    plots the sectors and the arcs\n",
    "    \"\"\"\n",
    "    patches = []\n",
    "    for ang, c in zip(ang_range, colors): \n",
    "        # sectors\n",
    "        patches.append(Wedge((0.,0.), .4, *ang, facecolor='w', lw=2))\n",
    "        # arcs\n",
    "        patches.append(Wedge((0.,0.), .4, *ang, width=0.10, facecolor=c, lw=2, alpha=0.5))\n",
    "    \n",
    "    [ax.add_patch(p) for p in patches]\n",
    "\n",
    "    \n",
    "    \"\"\"\n",
    "    set the labels (e.g. 'LOW','MEDIUM',...)\n",
    "    \"\"\"\n",
    "\n",
    "    for mid, lab in zip(mid_points, labels): \n",
    "\n",
    "        ax.text(0.35 * np.cos(np.radians(mid)), 0.35 * np.sin(np.radians(mid)), lab, \\\n",
    "            horizontalalignment='center', verticalalignment='center', fontsize=14, \\\n",
    "            fontweight='bold', rotation = rot_text(mid))\n",
    "\n",
    "    \"\"\"\n",
    "    set the bottom banner and the title\n",
    "    \"\"\"\n",
    "    r = Rectangle((-0.4,-0.1),0.8,0.1, facecolor='w', lw=2)\n",
    "    ax.add_patch(r)\n",
    "    \n",
    "    ax.text(0, -0.05, title, horizontalalignment='center', \\\n",
    "         verticalalignment='center', fontsize=22, fontweight='bold')\n",
    "\n",
    "    \"\"\"\n",
    "    plots the arrow now\n",
    "    \"\"\"\n",
    "    \n",
    "    pos = mid_points[abs(arrow - N)]\n",
    "    \n",
    "    ax.arrow(0, 0, 0.225 * np.cos(np.radians(pos)), 0.225 * np.sin(np.radians(pos)), \\\n",
    "                 width=0.04, head_width=0.09, head_length=0.1, fc='k', ec='k')\n",
    "    \n",
    "    ax.add_patch(Circle((0, 0), radius=0.02, facecolor='k'))\n",
    "    ax.add_patch(Circle((0, 0), radius=0.01, facecolor='w', zorder=11))\n",
    "\n",
    "    \"\"\"\n",
    "    removes frame and ticks, and makes axis equal and tight\n",
    "    \"\"\"\n",
    "    \n",
    "    ax.set_frame_on(False)\n",
    "    ax.axes.set_xticks([])\n",
    "    ax.axes.set_yticks([])\n",
    "    ax.axis('equal')\n",
    "    plt.tight_layout()\n",
    "    if fname:\n",
    "        fig.savefig(fname, dpi=200)\n",
    "\n",
    "#Analyse\n",
    "# Hole Wert an 0. Stelle im Dataframe.\n",
    "loc = df.iloc[0]['loc']\n",
    "\n",
    "# Errechne Level auf der Grundlage der Anzahl der Quelltextzeilen.\n",
    "def calculate_level(loc):\n",
    "    if loc <= 10000:\n",
    "        level=1\n",
    "    elif loc <= 50000:\n",
    "        level=2\n",
    "    elif loc <= 200000:\n",
    "        level=3\n",
    "    elif loc <= 500000:\n",
    "        level=4\n",
    "    else:\n",
    "        level=5\n",
    "    return(level)\n",
    "\n",
    "# Erstelle Gauge.\n",
    "gauge(labels=['Sehr klein','Klein','Mittel','Groß','Sehr groß'], \\\n",
    "        colors='RdYlGn', arrow=calculate_level(loc), title='Systemgröße')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 0,
        "height": 11,
        "hidden": false,
        "row": 14,
        "width": 4
       },
       "report_default": {
        "hidden": false
       }
      }
     }
    }
   },
   "source": [
    "## Testabdeckung\n",
    "\n",
    "In der Treemap Testabdeckung wird dargestellt, welche Pakete eine niedrige Testabdeckung haben. Die Testabdeckung ist das Verhältnis von den getroffenen Aussagen eines Testdurchlaufs im Verhältnis zu den möglichen Aussagen, die getroffen werden können. Das bedeutet, je höher die Testabdeckung ist, desto mehr eventuell auftauchenden Fehlern konnte vorgebeugt werden. Diese Analy-se ermöglicht es dem Entwickler einzuschätzen, welche Pakete nur wenig getestet wurden und somit geprüft werden müssen. Zusätzlich wird im Titel der Treemap für einen schnelleren Über-blick die gesamte Testabdeckung des Systems angegeben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 4,
        "height": 11,
        "hidden": false,
        "row": 14,
        "width": 8
       },
       "report_default": {
        "hidden": false
       }
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "#Testabdeckung\n",
    "\n",
    "#Cypher Abfrage\n",
    "import pandas as pd\n",
    "\n",
    "query =\"MATCH (p:Jacoco:Package)-[HAS_CLASS]->(c:Jacoco:Class)-[:HAS_METHOD]->(m:Method:Jacoco)-[:HAS_COUNTER]->(t:Counter) WHERE t.type='INSTRUCTION' AND p.name STARTS WITH 'org' RETURN p.name AS package, ((sum(t.covered)*100)/(sum(t.covered)+sum(t.missed)))/100.0 as coverage, sum(t.covered)+sum(t.missed) as loc ORDER BY loc DESC\"\n",
    "df = pd.DataFrame(graph.run(query).data())\n",
    "\n",
    "#Analyse\n",
    "# Erzeuge eine neue Spalte color und berechne die entsprechende Farbe in Abhängigkeit zu coverage.\n",
    "from matplotlib.cm import RdYlGn\n",
    "from matplotlib.colors import rgb2hex\n",
    "\n",
    "df['color'] = df['coverage'].apply(lambda x : rgb2hex(RdYlGn(x)))\n",
    "df.head()\n",
    "# Berechne den Mittelwert der Spalte coverage und speichere diesen in der Variable coverage.\n",
    "coverage = df['coverage'].mean()\n",
    "\n",
    "\n",
    "#Visualisierung ausgeben\n",
    "# Erstelle Treemap.\n",
    "import pygal\n",
    "treemap = pygal.Treemap(height=250, show_legend=False, \n",
    "                        value_formatter = lambda x: 'Größe: {} Zeilen '.format(x))\n",
    "treemap.title = 'Testabdeckung (Prozent bzw. grün=hoch & rot=gering) und Größe (Quelltextzeilen) auf Paketebene (gesamt: ' + str(coverage.round(2) * 100) + ' %)'\n",
    "for index, row in df.iterrows():\n",
    "    treemap.add(row['package'],\n",
    "                [{\"value\": row['loc'], \"label\": \"Testabdeckung: \" + str(row['coverage'] * 100) + \" %\",\n",
    "                  \"color\": row['color']}])\n",
    "display(HTML(base_html.format(rendered_chart=treemap.render(is_unicode=True))))\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 0,
        "height": 17,
        "hidden": false,
        "row": 25,
        "width": 4
       },
       "report_default": {
        "hidden": false
       }
      }
     }
    }
   },
   "source": [
    "## Programmierverstöße\n",
    "\n",
    "Im Radar Chart werden die Art der Programmierverstöße mit ihrer absoluten Anzahl dargestellt. Die Programmierverstöße werden in fünf Kategorien unterteilt. \n",
    "Dabei wird aufgezeigt, welche Qualität das Programm hinsichtlich Code Style, Error Prone, Multithreading, Best Practices und Design aufweist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 4,
        "height": 17,
        "hidden": false,
        "row": 25,
        "width": 8
       },
       "report_default": {
        "hidden": false
       }
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "#Programmierverstöße\n",
    "\n",
    "#Cypher Abfrage\n",
    "import pandas as pd\n",
    "\n",
    "query =\"MATCH (:Report)-[:HAS_FILE]->(file:File:Pmd)-[:HAS_VIOLATION]->(violation:Violation) RETURN  violation.ruleSet as category, count(violation.ruleSet) as frequency\"\n",
    "df = pd.DataFrame(graph.run(query).data())\n",
    "\n",
    "#Analyse\n",
    "# Hole Werte aus Spalten des Dataframes. Umwandlung dieser Werte in eine Liste.\n",
    "frequency=df['frequency'].tolist()\n",
    "category=df['category'].tolist()\n",
    "\n",
    "#Visualisierung\n",
    "# Erstelle Radar Chart.\n",
    "import pygal\n",
    "radar_chart = pygal.Radar(show_legend=False)\n",
    "radar_chart.title = 'Programmierverstöße'\n",
    "radar_chart.x_labels = category\n",
    "radar_chart.add('', frequency)\n",
    "\n",
    "display(HTML(base_html.format(rendered_chart=radar_chart.render(is_unicode=True))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 0,
        "height": 19,
        "hidden": false,
        "row": 42,
        "width": 4
       },
       "report_default": {
        "hidden": false
       }
      }
     }
    }
   },
   "source": [
    "## Entwickler mit den meisten Commits\n",
    "\n",
    "Im Balkendiagramm Entwickler mit den meisten Commits werden die zehn Entwickler mit den meisten Commits in Abhängigkeit der absoluten Anzahl ihrer Commits dargestellt.\n",
    "Hier erkennt man, welcher Entwickler den meisten Anteil an dem Entwickeln des Programmes hatte.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 4,
        "height": 19,
        "hidden": false,
        "row": 42,
        "width": 8
       },
       "report_default": {
        "hidden": false
       }
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "#Entwickler\n",
    "\n",
    "#Cypher Abfrage\n",
    "import pandas as pd\n",
    "\n",
    "query =\"MATCH (a:Author)-[:COMMITTED]->(c:Commit)-[:CONTAINS_CHANGE]->(:Change)-[:MODIFIES]->(file:File) WHERE NOT c:Merge RETURN a.name as developer, count(distinct c) as commits\"\n",
    "df = pd.DataFrame(graph.run(query).data())\n",
    "\n",
    "#Analyse\n",
    "# Sortiere das Dataframe nach der Anzahl der Commits (commits).\n",
    "df = df.sort_values('commits', ascending=False)\n",
    "\n",
    "# Extrahiere die ersten zehn Spalten und speichere sie im Dataframe developer_df.\n",
    "developer_df = df[0:10]\n",
    "developer_df.head(10)\n",
    "\n",
    "\n",
    "#Visualisierung\n",
    "\n",
    "import pygal\n",
    "bar_chart = pygal.HorizontalBar(show_legend=True, human_readable=True, \n",
    "fill=True, legend_at_bottom=True, legend_at_bottom_columns=2)\n",
    "bar_chart.title = 'Entwickler mit den meisten Commits'\n",
    "for index, row in developer_df.iterrows():\n",
    "     bar_chart.add(row['developer'],[{\"value\": row['commits']}])\n",
    "display(HTML(base_html.format(rendered_chart=bar_chart.render(is_unicode=True))))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 0,
        "height": 19,
        "hidden": false,
        "row": 61,
        "width": 4
       },
       "report_default": {
        "hidden": false
       }
      }
     }
    }
   },
   "source": [
    "## Größte Methoden\n",
    "\n",
    "Im Balkendiagramm Größte Methoden werden die zehn Methoden mit den meisten Quelltextzeilen in Abhängigkeit der absoluten Anzahl ihrer Quelltextzeilen dargestellt. Die größte Methode wird somit ermittelt.\n",
    "Große Methoden sind prädestiniert für Fehler und sollten im Rahmen des Reengineerngs überarbeitet werden, z.B. in kleinere aufgeteilt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 4,
        "height": 19,
        "hidden": false,
        "row": 61,
        "width": 8
       },
       "report_default": {
        "hidden": false
       }
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "#größte Methoden\n",
    "\n",
    "#Cypher Abfrage\n",
    "import pandas as pd\n",
    "\n",
    "query =\"MATCH (t:Type)-[:HAS_SOURCE]->(f), (t)-[:DECLARES]->(m:Method) RETURN DISTINCT t.fqn as type, m.signature as signature,  m.effectiveLineCount as loc, m.cyclomaticComplexity as complexity\"\n",
    "df = pd.DataFrame(graph.run(query).data())\n",
    "\n",
    "#Analyse\n",
    "\n",
    "# Sortiere das Dataframe nach der Anzahl der Quelltextzeilen (loc).\n",
    "df = df.sort_values('loc',ascending=False)\n",
    "# Extrahiere die Spalten loc, signature und type und speichere sie im Dataframe loc_df.\n",
    "loc_df = df[['loc','signature','type']][0:10]\n",
    "loc_df.head(10)\n",
    "\n",
    "\n",
    "#Visualisierung\n",
    "# Erstelle Bar Chart für loc.\n",
    "import pygal\n",
    "bar_chart = pygal.HorizontalBar(show_legend=True, human_readable=True, fill=True, legend_at_bottom=True, legend_at_bottom_columns=2)\n",
    "bar_chart.title = 'Größte Methoden'\n",
    "for index, row in loc_df.iterrows():\n",
    "    bar_chart.add(row['type'],[{\"value\": row['loc'], \"label\": row['signature']}])\n",
    "display(HTML(base_html.format(rendered_chart=bar_chart.render(is_unicode=True))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 0,
        "height": 21,
        "hidden": false,
        "row": 80,
        "width": 4
       },
       "report_default": {
        "hidden": false
       }
      }
     }
    }
   },
   "source": [
    "## Komplexeste Methoden\n",
    "Im Balkendiagramm Komplexeste Methoden werden die zehn Methoden der höchsten Komplexität in Abhängigkeit der absoluten Anzahl ihrer Quelltextzeilen dargestellt. Dabei werden die Anzahl der Rechenschritte /Speicherbedarf betrachtet.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 4,
        "height": 21,
        "hidden": false,
        "row": 80,
        "width": 8
       },
       "report_default": {
        "hidden": false
       }
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "#komplexeste Methoden\n",
    "\n",
    "#Cypher Abfrage\n",
    "import pandas as pd\n",
    "\n",
    "query =\"MATCH (t:Type)-[:HAS_SOURCE]->(f), (t)-[:DECLARES]->(m:Method) RETURN t.fqn as type, m.signature as signature,  sum(m.effectiveLineCount) as loc, sum(m.cyclomaticComplexity) as complexity\"\n",
    "df = pd.DataFrame(graph.run(query).data())\n",
    "\n",
    "#Analyse\n",
    "# Sortiere das Dataframe nach der zyklomatischen Komplexität (complexity).\n",
    "df = df.sort_values('complexity',ascending=False)\n",
    "\n",
    "# Extrahiere die Spalten complexity, signature und type und speichere sie im Dataframe complexity_df.\n",
    "complexity_df = df[['complexity','signature','type']][0:10]\n",
    "complexity_df.head(10)\n",
    "\n",
    "\n",
    "#Visualisierung\n",
    "import pygal \n",
    "bar_chart = pygal.HorizontalBar(show_legend=True, human_readable=True, fill=True, legend_at_bottom=True, legend_at_bottom_columns=2)\n",
    "bar_chart.title = 'Komplexeste Methoden'\n",
    "for index, row in complexity_df.iterrows():\n",
    "    bar_chart.add(row['type'],[{\"value\": row['complexity'], \"label\": row['signature']}])\n",
    "display(HTML(base_html.format(rendered_chart=bar_chart.render(is_unicode=True))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 0,
        "height": 19,
        "hidden": false,
        "row": 101,
        "width": 4
       },
       "report_default": {
        "hidden": false
       }
      }
     }
    }
   },
   "source": [
    "## Dateitypen\n",
    "Das vorliegende Kreisdiagramm Dateitypen visualisiert die prozentuale Häufigkeit der benutzten Dateitypen. Dateitypen mit einer absoluten Häufigkeit kleiner gleich 3 werden unter Andere zusammengefasst. Man kann damit das Programm näher kennenlernen und herausfinden, welche Programmiersprache am meisten eingesetzt wurde."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 4,
        "height": 19,
        "hidden": false,
        "row": 101,
        "width": 8
       },
       "report_default": {
        "hidden": false
       }
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "#Dateitypen\n",
    "\n",
    "#Cypher Abfrage\n",
    "import pandas as pd\n",
    "\n",
    "query =\"MATCH (f:Git:File) RETURN f.relativePath as relativePath\"\n",
    "df = pd.DataFrame(graph.run(query).data())\n",
    "#Analyse\n",
    "# Extrahiere Dateitypen aus Spalte des Dataframes.\n",
    "datatypes = df['relativePath'].str.rsplit('.', 1).str[1]\n",
    "\n",
    "# Zähle die Anzahl der Dateitypen und bilde diese in einem Series-Objekt ab.\n",
    "series = datatypes.value_counts()\n",
    "\n",
    "# Erzeuge zwei Listen aus dem Series-Objekt.\n",
    "datatype = list(series.index)\n",
    "frequency = list(series)\n",
    "\n",
    "# Erzeuge die Kategorie \"andere\", in der alle Dateitypen gesammelt werden, die weniger oder genau 20 mal auftauchen.\n",
    "andere = 0\n",
    "for wert in frequency[:]:\n",
    "    index = frequency.index(wert)\n",
    "    if wert <= 20:\n",
    "        andere += wert\n",
    "        datatype.remove(datatype[index])\n",
    "        frequency.remove(wert)\n",
    "frequency.append(andere)\n",
    "datatype.append(\"andere\")\n",
    "\n",
    "#Visualisierung\n",
    "import pygal \n",
    "pie_chart = pygal.Pie()\n",
    "pie_chart.title = 'Dateitypen'\n",
    "for einzelneDateitypen in datatype:\n",
    "    index= datatype.index(einzelneDateitypen)\n",
    "    anzahl=frequency[index]\n",
    "    pie_chart.add(einzelneDateitypen, anzahl)\n",
    "display(HTML(base_html.format(rendered_chart=pie_chart.render(is_unicode=True))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 0,
        "height": 5,
        "hidden": false,
        "row": 120,
        "width": 12
       },
       "report_default": {}
      }
     }
    }
   },
   "source": [
    "## Toxicity Chart\n",
    "Das Toxicity Chart gibt die giftigste Klasse des Softwaresystems aus. Dazu wird der Giftigkeitsgrad anhand selbst festgelegter Metriken (hier: ClassFanOutComplexity, CyclomaticCom-plexity, MethodLength und ParameterNumber) und deren Schwellenwerte (hier: 30, 10, 30, 6) bestimmt. Der Giftigkeitsgrad wird in einem gestapelten Säulendiagramm veranschaulicht, das die einzelnen Anteile der Metriken, die den Giftigkeitsgrad bestimmen, anzeigen. Anhand dieser Analyse erkennt man schnell Klassen, die Probleme aufweisen können und somit einen hohen Wartungsaufwand verursachen können."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 0,
        "height": 29,
        "hidden": false,
        "row": 125,
        "width": null
       },
       "report_default": {}
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "#Cypher Abfrage\n",
    "import pandas as pd\n",
    "\n",
    "classfanoutcomplexity_query =\"MATCH (c:Type)-[:DEPENDS_ON]->(d:Type) WHERE NOT c.name CONTAINS '$' RETURN DISTINCT c.fqn as Type, count(d) AS ClassFanOutComplexity ORDER BY ClassFanOutComplexity DESC\"\n",
    "classfanoutcomplexity_df = pd.DataFrame(graph.run(classfanoutcomplexity_query).data())\n",
    "\n",
    "cyclomaticcomplexity_query =\"MATCH (c:Type)-[DECLARES]->(m:Method) WHERE NOT c.name CONTAINS '$' AND EXISTS(m.cyclomaticComplexity) RETURN DISTINCT m.signature AS Method, c.fqn AS Type, m.cyclomaticComplexity as CyclomaticComplexity ORDER BY CyclomaticComplexity DESC\"\n",
    "cyclomaticComplexity_df = pd.DataFrame(graph.run(cyclomaticcomplexity_query).data())\n",
    "\n",
    "methodlength_query =\"MATCH (c:Type)-[DECLARES]->(m:Method) WHERE NOT c.name CONTAINS '$' AND EXISTS(m.effectiveLineCount) RETURN DISTINCT m.signature AS Method, c.fqn AS Type, m.effectiveLineCount AS MethodLength ORDER BY MethodLength DESC\"\n",
    "methodLength_df = pd.DataFrame(graph.run(methodlength_query).data())\n",
    "\n",
    "parameternumber_query =\"MATCH (c:Type)-[DECLARES]->(m:Method)-[HAS]->(p:Parameter) WHERE NOT c.name CONTAINS '$' RETURN m.signature AS Method, c.fqn AS Type, count(p) AS ParameterNumber ORDER BY ParameterNumber DESC\"\n",
    "parameterNumber_df = pd.DataFrame(graph.run(parameternumber_query).data())\n",
    "\n",
    "# Analyse\n",
    "# Entferne alle Klassen, die weniger als 30 Abhängigkeiten zu anderen Klassen besitzen.\n",
    "classfanoutcomplexity_df.drop(classfanoutcomplexity_df[classfanoutcomplexity_df['ClassFanOutComplexity'] < 30 ].index , inplace=True)\n",
    "\n",
    "\n",
    "# Entferne alle Methoden, deren zyklomatische Komplexität kleiner als 10 ist.\n",
    "cyclomaticComplexity_df.drop(cyclomaticComplexity_df[cyclomaticComplexity_df['CyclomaticComplexity']<10].index, inplace=True)\n",
    "\n",
    "\n",
    "# Entferne alle Methoden, deren Anzahl der Quelltextzeilen kleiner als 30 ist.\n",
    "methodLength_df.drop(methodLength_df[methodLength_df['MethodLength'] < 30 ].index , inplace=True)\n",
    "\n",
    "\n",
    "# Entferne alle Methoden, die weniger als 6 Paramter besitzen.\n",
    "parameterNumber_df.drop(parameterNumber_df[parameterNumber_df['ParameterNumber'] < 6 ].index , inplace=True)\n",
    "\n",
    "\n",
    "# Die drei Dataframes mit Methodenmetriken werden zusammengeführt und im Dataframe method_metrics_df abgebildet.\n",
    "method_metrics_df = pd.merge(cyclomaticComplexity_df, methodLength_df[['Type', 'MethodLength']], how='outer', on = 'Type').merge(parameterNumber_df[['Type', 'ParameterNumber']], how='outer', on = 'Type')\n",
    "\n",
    "\n",
    "# Fehlende Werte werden auf 0 gesetzt.\n",
    "method_metrics_df = method_metrics_df.fillna(0)\n",
    "\n",
    "\n",
    "# Die Dataframes classfanoutcomplexity_df und method_metrics_df werden zusammengeführt.\n",
    "toxicity_df = pd.merge(classfanoutcomplexity_df, method_metrics_df, how='outer', on = 'Type')\n",
    "\n",
    "# Fehlende Werte werden auf 0 gesetzt.\n",
    "toxicity_df= toxicity_df.fillna(0)\n",
    "\n",
    "\n",
    "# Berechne den Toxicity-Wert für ClassFanOutComplexity.\n",
    "toxicity_df['ClassFanOutComplexity'] = toxicity_df['ClassFanOutComplexity'].apply(lambda value: value/30)\n",
    "\n",
    "# Berechne den Toxicity-Wert für CyclomaticComplexity.\n",
    "toxicity_df['CyclomaticComplexity'] = toxicity_df['CyclomaticComplexity'].apply(lambda value: value/10)\n",
    "\n",
    "# Berechne den Toxicity-Wert für MethodLength.\n",
    "toxicity_df['MethodLength'] = toxicity_df['MethodLength'].apply(lambda value: value/30)\n",
    "\n",
    "# Berechne den Toxicity-Wert für ParameterNumber.\n",
    "toxicity_df['ParameterNumber'] = toxicity_df['ParameterNumber'].apply(lambda value: value/6)\n",
    "\n",
    "# Erzeuge die Spalte ToxicityScore und berechne die Zeilensumme aus ClassFanOutComplexity, CyclomaticComplexity, MethodLength und ParameterNumber.\n",
    "toxicity_df['ToxicityScore'] = toxicity_df.ClassFanOutComplexity + toxicity_df.CyclomaticComplexity + toxicity_df.MethodLength + toxicity_df.ParameterNumber\n",
    "\n",
    "# Sortiere alle Werte absteigend nach dem ToxicityScore.\n",
    "toxicity_df = toxicity_df.sort_values('ToxicityScore', ascending=False)\n",
    "\n",
    "import pygal\n",
    "stacked_bar_chart = pygal.StackedBar(show_legend=True, human_readable=True, fill=False, x_label_rotation=90, truncate_label=-1, truncate_legend=-1)\n",
    "stacked_bar_chart.title = 'Toxicity Chart'\n",
    "stacked_bar_chart.x_labels = toxicity_df['Type'].tolist()\n",
    "stacked_bar_chart.add('ClassFanOutComplexity', toxicity_df['ClassFanOutComplexity'].tolist())\n",
    "stacked_bar_chart.add('CyclomaticComplexity', toxicity_df['CyclomaticComplexity'].tolist())\n",
    "stacked_bar_chart.add('MethodLength', toxicity_df['MethodLength'].tolist())\n",
    "stacked_bar_chart.add('ParameterNumber', toxicity_df['ParameterNumber'].tolist())\n",
    "display(HTML(base_html.format(rendered_chart=stacked_bar_chart.render(is_unicode=True))))\n"
   ]
  }
 ],
 "metadata": {
  "extensions": {
   "jupyter_dashboards": {
    "activeView": "grid_default",
    "version": 1,
    "views": {
     "grid_default": {
      "cellMargin": 10,
      "defaultCellHeight": 20,
      "maxColumns": 12,
      "name": "grid",
      "type": "grid"
     },
     "report_default": {
      "name": "report",
      "type": "report"
     }
    }
   }
  },
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
